{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c55338-562f-4e89-95e7-07b4b74dc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a01086-702a-4192-a391-77531159055d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05a6bb2c-7e01-453f-a6bb-c1cc3788a693",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tensor addition simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42063da3-062c-4a07-ac0e-6a3848306ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.6, 0.98], [0.37, 0.45]])\n",
    "y = torch.tensor([[0.58, 0.23], [0.11, 0.07]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca43a6c7-c11d-468d-9cc5-783213935fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d137fed-2d14-4a5f-a92f-678ab79eee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000, 0.9800],\n",
       "        [0.3700, 0.4500]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f03b08f-b96a-43c9-8fc6-1a2a698e3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac5142c-7ee9-4bd2-b23a-9adb4b60ed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1800, 1.2100],\n",
       "        [0.4800, 0.5200]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b154be28-443a-4ad0-a8a0-4c6431dae25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.98 + 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3ed20-53b1-44ff-8a0a-4257a987d659",
   "metadata": {},
   "source": [
    "## Tensor addition with different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b20fd4a5-7e7d-4639-97c1-bdccb1d6f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 1, 3, 3)\n",
    "y = torch.rand(1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d462cab-f011-4b08-8792-d57c4ce6f00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8920, 0.4217, 0.0935],\n",
       "          [0.5344, 0.5840, 0.1415],\n",
       "          [0.7096, 0.9402, 0.5615]]],\n",
       "\n",
       "\n",
       "        [[[0.5587, 0.8196, 0.9880],\n",
       "          [0.5417, 0.3123, 0.5779],\n",
       "          [0.5303, 0.1155, 0.6764]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0424e986-3b64-46f5-9eb1-aa57adcfbff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8919512033462524"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0][0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585cd0f5-1e32-4ec3-bd5d-0210280dc66e",
   "metadata": {},
   "source": [
    "<b>Rule: </b> <br>If tensors have a different number of dimensions, the tensor with fewer dimensions is padded with ones on the left side until it matches the number of dimensions of the larger tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586f0a5-0439-4721-a9c1-a2ef6e2dc052",
   "metadata": {},
   "source": [
    "y shape: (1, 3, 1) â†’ (1, 1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64f93c16-a7a5-4159-9666-b1e8b9593168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5479],\n",
       "         [0.0342],\n",
       "         [0.0426]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56690b8c-717a-4f12-b5ad-9b334a3af011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5479)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851ebb8-a034-46e9-9a7a-e8488ddd810d",
   "metadata": {},
   "source": [
    "<b><h2>Broadcast Rule - Dimension Compatibility </b>\n",
    "PyTorch now checks each dimension from right to left to determine if broadcasting can occur:\n",
    "\n",
    "<h3>4th Dimension (rightmost):</h3>\n",
    "\n",
    "x: 3<br>\n",
    "y: 1\n",
    "<br>Result: These dimensions are compatible because 1 can be broadcasted to 3. Tensor y will be expanded to have a size of 3 in this dimension.<br>\n",
    "<br><h3>3rd Dimension:</h3>\n",
    "\n",
    "x: 3<br>\n",
    "y: 3<br>\n",
    "Result: These dimensions are already equal, so no broadcasting is needed.<br><br>\n",
    "<h3>2nd Dimension:</h3>\n",
    "\n",
    "x: 1<br>\n",
    "y: 1<br>\n",
    "Result: These dimensions are equal, so no broadcasting is needed.<br><br>\n",
    "<h3>1st Dimension (leftmost):</h3>\n",
    "\n",
    "x: 2<br>\n",
    "y: 1<br>\n",
    "Result: The dimension 1 in y can be broadcasted to match the dimension 2 in x.\n",
    "<br><br><h3>At this point, the shape of y has been broadcasted from (1, 1, 3, 1) to (2, 1, 3, 3) to match the shape of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acad6064-3222-4f30-a077-37ae7a8ec997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1000,  2.1000,  3.1000],\n",
      "          [ 4.2000,  5.2000,  6.2000],\n",
      "          [ 7.3000,  8.3000,  9.3000]]],\n",
      "\n",
      "\n",
      "        [[[10.1000, 11.1000, 12.1000],\n",
      "          [13.2000, 14.2000, 15.2000],\n",
      "          [16.3000, 17.3000, 18.3000]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[[1.0, 2.0, 3.0],\n",
    "                    [4.0, 5.0, 6.0],\n",
    "                    [7.0, 8.0, 9.0]]],\n",
    "\n",
    "                  [[[10.0, 11.0, 12.0],\n",
    "                    [13.0, 14.0, 15.0],\n",
    "                    [16.0, 17.0, 18.0]]]])\n",
    "\n",
    "y = torch.tensor([[[[0.1], [0.2], [0.3]]]])\n",
    "\n",
    "# Perform addition\n",
    "z = x + y\n",
    "\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cfcc406-13a7-42ed-8f19-9e5f9f9814e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.3000, 8.3000, 9.3000])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42714dc9-2eb2-4694-af1f-17e8b5d5259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.3000, 8.3000, 9.3000])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0][0][2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
